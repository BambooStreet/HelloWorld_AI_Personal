{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference test\n",
    "\n",
    "# from flask import Flask, request, jsonify\n",
    "# from flask_cors import CORS\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "#from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_mongodb.vectorstores import MongoDBAtlasVectorSearch\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "CONFIG_NAME = \"mongo_config.json\"\n",
    "\n",
    "# 현재 작업 디렉토리를 얻습니다.\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# .env 파일의 경로를 지정합니다.\n",
    "dotenv_path = os.path.join(current_dir, 'model', '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "print(\"## config_name : \", CONFIG_NAME)\n",
    "\n",
    "with open(f'configs/{CONFIG_NAME}', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "if config['db'] == 'elasticsearch':\n",
    "    os.environ[\"ES_CLOUD_ID\"] = os.getenv(\"ES_CLOUD_ID\")\n",
    "    os.environ[\"ES_USER\"] = os.getenv(\"ES_USER\")\n",
    "    os.environ['ES_PASSWOR'] = os.getenv(\"ES_PASSWORD\")\n",
    "    os.environ[\"ES_API_KEY\"] = os.getenv(\"ES_API_KEY\")\n",
    "\n",
    "elif config['db'] == 'mongo':\n",
    "   os.environ[\"MONGODB_ATLAS_CLUSTER_URI\"] = os.getenv(\"MONGODB_ATLAS_CLUSTER_URI\")\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")\n",
    "# 대화 기록을 저장할 딕셔너리\n",
    "conversations = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DB once at startup\n",
    "db = None\n",
    "\n",
    "try:\n",
    "    if config['db'] == 'elasticsearch':\n",
    "        db = ElasticsearchStore(\n",
    "            index_name='helloworld',\n",
    "            embedding=OpenAIEmbeddings()\n",
    "        )\n",
    "    elif config['db'] == 'mongo':\n",
    "        client = MongoClient(os.environ[\"MONGODB_ATLAS_CLUSTER_URI\"])\n",
    "        \n",
    "        MONGODB_COLLECTION = client[config['path']['db_name']][config['path']['collection_name']]\n",
    "        db = MongoDBAtlasVectorSearch(\n",
    "            collection = MONGODB_COLLECTION,\n",
    "            embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "            index_name = config['path']['collection_name'],\n",
    "            relevance_score_fn = \"cosine\" # [cosine, euclidean, dotProduct]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Wrong db value setted in config file\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading database: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT 연동\n",
    "def generate_ai_response(conversation_history,query,db):\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=config['openai_chat_inference']['model'],\n",
    "        frequency_penalty=config['openai_chat_inference']['frequency_penalty'],\n",
    "        logprobs=config['openai_chat_inference']['logprobs'],\n",
    "        top_logprobs=config['openai_chat_inference']['top_logprobs'],\n",
    "        max_tokens=config['chat_inference']['max_new_tokens'],  # 최대 토큰수\n",
    "        temperature=config['chat_inference']['temperature'],  # 창의성 (0.0 ~ 2.0)\n",
    "    )\n",
    "\n",
    "    template_text = \"\"\"\n",
    "    당신은 한국의 외국인 근로자를 위한 법률 및 비자 전문 AI 어시스턴트입니다. 다음 지침을 따라 응답해 주세요:\n",
    "\n",
    "    1. 관련 문서의 정보를 바탕으로 정확하고 최신의 법률 및 비자 정보를 제공하세요.\n",
    "    2. 복잡한 법률 용어나 절차를 쉽게 설명하여 외국인 근로자가 이해하기 쉽게 답변하세요.\n",
    "    3. 불확실한 정보에 대해서는 명확히 언급하고, 공식 기관에 문의할 것을 권장하세요.\n",
    "    4. 문화적 차이를 고려하여 정중하고 친절한 태도로 응대하세요.\n",
    "    5. 필요한 경우 관련 정부 기관이나 지원 센터의 연락처를 제공하세요.\n",
    "    6. 개인정보 보호를 위해 구체적인 개인 정보를 요구하지 마세요.\n",
    "    7. 이전 대화 내용을 참고하여 문맥에 맞는 자연스러운 응답을 제공하세요.\n",
    "    8. 사용자의 이전 질문이나 concerns를 기억하고 연관된 정보를 제공하세요.\n",
    "\n",
    "    관련 문서: \n",
    "    {context}\n",
    "\n",
    "    대화 기록:\n",
    "    {conversation_history}\n",
    "    \"\"\"\n",
    "\n",
    "    similar_docs = db.similarity_search(query, k=3)\n",
    "    print('query:',query)\n",
    "    print('similar_docs:',similar_docs)\n",
    "\n",
    "    # 검색된 문서의 내용을 하나의 문자열로 결합\n",
    "    context = \" \".join([doc.page_content for doc in similar_docs])\n",
    "    \n",
    "\n",
    "    # 템플릿 설정\n",
    "    prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "    # 템플릿에 값을 채워서 프롬프트를 완성\n",
    "    filled_prompt = prompt_template.format(context = context, conversation_history= conversation_history)\n",
    "    \n",
    "    output = llm.invoke(input = filled_prompt)\n",
    "    \n",
    "    return output.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    text = input()\n",
    "    print('user:',text)\n",
    "    if text == 'Q':\n",
    "        break\n",
    "    data = {\"Conversation\":[{\"speaker\":\"human\",\"utterance\":f\"{text}\"}]}\n",
    "\n",
    "    # 새로운 쿼리 형식 처리\n",
    "    conversation = data.get('Conversation', [])\n",
    "\n",
    "    # 마지막 human 발화 추출\n",
    "    user_query = next((item['utterance'] for item in reversed(conversation) if item['speaker'] == 'human'), None)\n",
    "\n",
    "    # AI 응답 생성\n",
    "    answer = generate_ai_response(conversation, user_query, db)\n",
    "    print('bot:',answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "\n",
    "# MongoDB 연결 설정\n",
    "client = MongoClient(os.getenv(\"MONGODB_ATLAS_CLUSTER_URI\"))\n",
    "db_name = \"HelloWorld-AI\"  # 실제 데이터베이스 이름으로 변경\n",
    "collection_name = \"foreigner_legalQA\"  # 실제 컬렉션 이름으로 변경\n",
    "db = client[db_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# 데이터베이스 연결 확인\n",
    "print(f\"Database names: {client.list_database_names()}\")\n",
    "print(f\"Collection names in {db_name}: {db.list_collection_names()}\")\n",
    "\n",
    "# 컬렉션에 데이터가 있는지 확인\n",
    "doc_count = collection.count_documents({})\n",
    "print(f\"Number of documents in collection: {doc_count}\")\n",
    "\n",
    "# OpenAI Embeddings 초기화\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Vector Store 초기화\n",
    "index_name = \"vector_index\"  # 실제 인덱스 이름으로 변경\n",
    "try:\n",
    "    vector_store = MongoDBAtlasVectorSearch(\n",
    "        collection=collection,\n",
    "        embedding=embedding,\n",
    "        index_name=index_name\n",
    "        embedding_key=\"embedding\"\n",
    "    )\n",
    "    print(\"Vector store initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing vector store: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 쿼리 실행\n",
    "query = \"한국의 노동 휴게시간\"\n",
    "try:\n",
    "    similar_docs = vector_store.similarity_search(query, k=3)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Number of similar docs found: {len(similar_docs)}\")\n",
    "    for i, doc in enumerate(similar_docs):\n",
    "        print(f\"Document {i+1}:\")\n",
    "        print(f\"Content: {doc.page_content[:100]}...\")  # 처음 100자만 출력\n",
    "        print(f\"Metadata: {doc.metadata}\")\n",
    "        print(\"---\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during similarity search: {e}\")\n",
    "\n",
    "# 벡터 인덱스 정보 확인\n",
    "try:\n",
    "    index_info = collection.index_information()\n",
    "    print(\"Vector index information:\")\n",
    "    print(json.dumps(index_info, indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Error getting index information: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
